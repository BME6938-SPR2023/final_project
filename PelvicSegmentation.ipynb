{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BME6938-SPR2023/final_project/blob/main/PelvicSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "vyPmxOfPG4s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets evaluate"
      ],
      "metadata": {
        "id": "bF3VxLNvHWwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6cea796-e130-4ac4-a046-a7bc47cee9d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import libraries"
      ],
      "metadata": {
        "id": "HZNC0x-FHaTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NEED to delect unused libraries\n",
        "import os as os\n",
        "from glob import glob\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "import evaluate\n",
        "import multiprocessing\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "import torch\n",
        "import cv2\n",
        "import PIL\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.transform import resize, rotate\n",
        "# import SimpleITK as sitk\n",
        "from datasets.dataset_dict import DatasetDict\n",
        "from datasets import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from transformers import SegformerFeatureExtractor,SegformerImageProcessor, AutoImageProcessor, TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "6JVTvjjEHZGb"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HF Login"
      ],
      "metadata": {
        "id": "OfcXr5iLAjW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "57d26d2a0c85483b819b730428df1db0",
            "076aa2d8a1c24cf29e0382a5f50d1c5c",
            "d46143b4c50946c6ac4dfe35dadd2769",
            "001e152e0aa045a7900e9391cd28d65b",
            "316c9759bc0643a5b60ea75d785a37e1",
            "a5800fd8a0ac4c5580b04d62d5bf16c7",
            "1d478e1dbd834648ba8bd481a1945c04",
            "870e2d453d794cc0be3b4a7486cb73ab",
            "af909819456049cba15fb2d19b76cea1",
            "f9d92b91ce2b4291bbddd5231e214d53",
            "8359b8b4acb348d8ad95d5cdca5b26a8",
            "9a7b8641acc34bf289663fc9ca4e193a",
            "26581b71da7a45bd88f0ad5968abe28c",
            "9671295fb7df4ea88365046e939b662b",
            "2a4867ca09b348f6b962d4cc345956de",
            "132603c40cc9487eb6c9fe5fe711bd64",
            "52455886f6f24be8a8f07fe1ed8a1786"
          ]
        },
        "id": "cdyEqCT4Ai1X",
        "outputId": "0c4012c3-bbd7-4806-ff0f-62b2b8ec6ce9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_username = \"ashiyakatuka11\""
      ],
      "metadata": {
        "id": "2kjNglpuAqxI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation: \n",
        "#### convert nii to png and remove slices without matching labels\n",
        "- Resized and rotated images \n",
        "- Reduced the dataset by only including images that match with segmentation masks with 1 or both labels\n",
        "- There is an option for converting from .nii to .png"
      ],
      "metadata": {
        "id": "QfFTkPPFJVXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data cleaning 1: use stacked data/ labels to get label list\n",
        "def clean_data(input_folder, output_folder, image_processor): \n",
        "  #first remove matched images without labels\n",
        "\n",
        "  img_folder_path = '/stacked_sliced/train' #switch \"train\" to \"test\"\n",
        "  lbl_folder_path = '/prostate_femur_sliced/train'\n",
        "\n",
        "  img_dir = input_folder + img_folder_path\n",
        "  label_dir = input_folder + lbl_folder_path\n",
        "\n",
        "  labels_paths = []\n",
        "\n",
        "  img_paths = sorted([os.path.join( img_dir, x) for x in os.listdir( img_dir)])\n",
        "  labels_paths = sorted([os.path.join(label_dir, x) for x in os.listdir(label_dir)])\n",
        "\n",
        "  for i_img,i_mask in zip(img_paths,labels_paths):\n",
        "    img_rename = os.path.splitext(os.path.basename(i_img))[0]\n",
        "    label_rename = os.path.splitext(os.path.basename(i_mask))[0]\n",
        "\n",
        "    Reading_Img_NII = nib.load(i_img)\n",
        "    Reading_Label_NII = nib.load(i_mask)\n",
        "\n",
        "    img_arr = Reading_Img_NII.get_fdata()\n",
        "    mask_arr = Reading_Label_NII.get_fdata()\n",
        "    \n",
        "     # Define the new size for the resized image\n",
        "    new_size = (512, 512)\n",
        "    \n",
        "    # Resize the image using the resize() function from skimage\n",
        "    img_resized = resize(img_arr, new_size, anti_aliasing=True)\n",
        "    mask_resized = resize(mask_arr, new_size, anti_aliasing=True)\n",
        "\n",
        "    # Rotate the image using the rotate() function from skimage\n",
        "    angle = 90\n",
        "    img_resized = rotate(img_resized , angle)\n",
        "    mask_resized = rotate(mask_resized, angle)\n",
        "\n",
        "    # Normalized \n",
        "    img_arr_norm = (img_resized- img_resized.min()) / (img_resized.max() - img_resized.min())\n",
        "    pil_image = Image.fromarray((img_arr_norm * 255).astype(np.uint8))\n",
        "\n",
        "    label_arr_norm = (mask_resized - mask_resized.min()) / (mask_resized .max() - mask_resized.min())\n",
        "    pil_label = Image.fromarray((label_arr_norm* 255).astype(np.uint8)) \n",
        "\n",
        "    pil_image_T = np.stack([pil_image ] * 3, axis=-1).transpose((2,1,0))\n",
        "    encoded_inputs = image_processor(pil_image_T, pil_label, return_tensors=\"pt\")\n",
        "\n",
        "    labels = encoded_inputs[\"labels\"].squeeze().unique()\n",
        "    if len(labels) > 2:\n",
        "      labels_paths.append(i_mask )\n",
        "      print(i_img)\n",
        "      #save stack slices with labels\n",
        "      pil_image.save(f'/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack2{img_folder_path}/{img_rename}.png')\n",
        "      pil_label.save(f'/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack2{lbl_folder_path}/{label_rename}.png')\n",
        "  return(labels_paths)"
      ],
      "metadata": {
        "id": "MCp2mOQYJirH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data2(input_folder,output_folder):\n",
        "  img_folder_path = '/T2_sliced/test' #switch \"train\" to \"test\"\n",
        "  lbl_folder_path = '/prostate_femur_sliced/test'\n",
        "  newlbl_folder_path = '/prostate_femur_sliced/test'\n",
        "\n",
        "  img_dir = input_folder + img_folder_path\n",
        "  label_dir = input_folder + lbl_folder_path\n",
        "  newlabel_dir = output_folder + lbl_folder_path\n",
        "\n",
        "  img_paths = sorted([os.path.join(img_dir, x) for x in os.listdir(img_dir)])\n",
        "  labels_paths = sorted([os.path.join(label_dir, x) for x in os.listdir(label_dir)])\n",
        "  newlabels_paths = sorted([os.path.join(newlabel_dir, x) for x in os.listdir(newlabel_dir)])\n",
        "\n",
        "  for i_img,i_mask in zip(img_paths,labels_paths):\n",
        "    img_rename = os.path.splitext(os.path.basename(i_img))[0]\n",
        "    label_rename = os.path.splitext(os.path.basename(i_mask))[0]\n",
        "    for new_mask in newlabels_paths:\n",
        "      newlabel_rename = os.path.splitext(os.path.basename(new_mask))[0]\n",
        "      if (label_rename == newlabel_rename):\n",
        "        Reading_Img_NII = nib.load(i_img)\n",
        "        # Reading_Label_NII = nib.load(i_mask)\n",
        "\n",
        "        img_arr = Reading_Img_NII.get_fdata()\n",
        "        # mask_arr = Reading_Label_NII.get_fdata()\n",
        "        \n",
        "        # Define the new size for the resized image\n",
        "        new_size = (512, 512)\n",
        "        \n",
        "        # Resize the image using the resize() function from skimage\n",
        "        img_resized = resize(img_arr, new_size, anti_aliasing=True)\n",
        "        # mask_resized = resize(mask_arr, new_size, anti_aliasing=True)\n",
        "\n",
        "        # Rotate the image using the rotate() function from skimage\n",
        "        angle = 90\n",
        "        img_resized = rotate(img_resized , angle)\n",
        "        # mask_resized = rotate(mask_resized, angle)\n",
        "\n",
        "        img_arr_norm = (img_resized- img_resized.min()) / (img_resized.max() - img_resized.min())\n",
        "        pil_image = Image.fromarray((img_arr_norm * 255).astype(np.uint8))\n",
        "\n",
        "        # label_arr_norm = (mask_resized - mask_resized.min()) / (mask_resized .max() - mask_resized.min())\n",
        "        # pil_label = Image.fromarray((label_arr_norm* 255).astype(np.uint8))\n",
        "\n",
        "        print(i_img)\n",
        "        #save stack slices with labels\n",
        "        pil_image.save(f'/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack2{img_folder_path}/{img_rename}.png')\n",
        "        # pil_image.save(f'/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack2{lbl_folder_path}/{label_rename}.png')\n",
        "  print(\"Done\")\n"
      ],
      "metadata": {
        "id": "LffbuE4VJmXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack\" #folder with original images\n",
        "output_path = \"/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack2\" #folder where new images will be saved"
      ],
      "metadata": {
        "id": "9fESy19sJymh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_processor = SegformerImageProcessor(use_python_backend=False)\n"
      ],
      "metadata": {
        "id": "lNCPJcLwJ7Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data(folder_path,output_path, image_processor) #Run ONLY TWICE for stacked/label train and stacked/label test\n"
      ],
      "metadata": {
        "id": "QHtW-aSYCO2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data2(folder_path,output_path) #Run 4 times for T2 and dCT2  train and T2 and dCT2l test"
      ],
      "metadata": {
        "id": "UnX3sfzmCQfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### .nii reduced"
      ],
      "metadata": {
        "id": "DX1fpSe0kBe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data cleaning 1: use stacked data/ labels to get label list\n",
        "import shutil\n",
        "def reduced_data(input_folder, output_path, image_processor): \n",
        "  #first remove matched images without labels\n",
        " \n",
        "  img_folder_path = '/stacked_sliced/train' #switch \"train\" to \"test\"\n",
        "  lbl_folder_path = '/prostate_femur_sliced/train'\n",
        "\n",
        "  # new_folder_path = newfolder/img_folder_path\n",
        "  # !mkdir /content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack_reduced/stacked_sliced/test\n",
        "  # !mkdir /content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack_reduced/stacked_sliced/test\n",
        "\n",
        "  img_dir = input_folder + img_folder_path\n",
        "  label_dir = input_folder + lbl_folder_path\n",
        "\n",
        "  out_img_dir = output_path + img_folder_path\n",
        "  out_lbl_dir = output_path + lbl_folder_path\n",
        "\n",
        "  labels_paths = []\n",
        "\n",
        "  img_paths = sorted([os.path.join( img_dir, x) for x in os.listdir( img_dir)])\n",
        "  labels_paths = sorted([os.path.join(label_dir, x) for x in os.listdir(label_dir)])\n",
        "\n",
        "  for i_img,i_mask in zip(img_paths,labels_paths):\n",
        "    img_rename = os.path.splitext(os.path.basename(i_img))\n",
        "    label_rename = os.path.splitext(os.path.basename(i_mask))\n",
        "\n",
        "    Reading_Img_NII = nib.load(i_img)\n",
        "    Reading_Label_NII = nib.load(i_mask)\n",
        "\n",
        "    img_arr = Reading_Img_NII.get_fdata()\n",
        "    mask_arr = Reading_Label_NII.get_fdata()\n",
        "    \n",
        "     # Define the new size for the resized image\n",
        "    new_size = (512, 512)\n",
        "    \n",
        "    # Resize the image using the resize() function from skimage\n",
        "    img_resized = resize(img_arr, new_size, anti_aliasing=True)\n",
        "    mask_resized = resize(mask_arr, new_size, anti_aliasing=True)\n",
        "\n",
        "    # Rotate the image using the rotate() function from skimage\n",
        "    angle = 90\n",
        "    img_resized = rotate(img_resized , angle)\n",
        "    mask_resized = rotate(mask_resized, angle)\n",
        "\n",
        "    img_arr_norm = (img_resized- img_resized.min()) / (img_resized.max() - img_resized.min())\n",
        "    pil_image = Image.fromarray((img_arr_norm * 255).astype(np.uint8))\n",
        "\n",
        "    label_arr_norm = (mask_resized - mask_resized.min()) / (mask_resized .max() - mask_resized.min())\n",
        "    pil_label = Image.fromarray((label_arr_norm* 255).astype(np.uint8)) \n",
        "\n",
        "    pil_image_T = np.stack([pil_image ] * 3, axis=-1).transpose((2,1,0))\n",
        "    encoded_inputs = image_processor(pil_image_T, pil_label, return_tensors=\"pt\")\n",
        "\n",
        "    labels = encoded_inputs[\"labels\"].squeeze().unique()\n",
        "    if len(labels) > 2:\n",
        "      labels_paths.append(i_mask )\n",
        "      print(i_img)\n",
        "      #save stack slices with labels\n",
        "      shutil.copy(i_img, out_img_dir )\n",
        "      # shutil.copy(i_mask,out_lbl_dir )\n",
        "  return(labels_paths)"
      ],
      "metadata": {
        "id": "pWA0ibB7kBNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduced_data2(input_folder,output_path):\n",
        "  img_folder_path = '/stacked_sliced/train' #switch \"train\" to \"test\"\n",
        "  lbl_folder_path = '/prostate_femur_sliced/train'\n",
        "  newlbl_folder_path = '/prostate_femur_sliced/test'\n",
        "\n",
        "  img_dir = input_folder + img_folder_path\n",
        "  label_dir = input_folder + lbl_folder_path\n",
        "  newlabel_dir = output_path + lbl_folder_path\n",
        "\n",
        "  out_img_dir = output_path + img_folder_path\n",
        "  # out_lbl_dir = output_path + lbl_folder_path\n",
        "\n",
        "  img_paths = sorted([os.path.join(img_dir, x) for x in os.listdir(img_dir)])\n",
        "  labels_paths = sorted([os.path.join(label_dir, x) for x in os.listdir(label_dir)])\n",
        "  newlabels_paths = sorted([os.path.join(newlabel_dir, x) for x in os.listdir(newlabel_dir)])\n",
        "\n",
        "  for i_img,i_mask in zip(img_paths,labels_paths):\n",
        "    img_rename = os.path.splitext(os.path.basename(i_img))\n",
        "    label_rename = os.path.splitext(os.path.basename(i_mask))\n",
        "    for new_mask in newlabels_paths:\n",
        "      newlabel_rename = os.path.splitext(os.path.basename(new_mask))\n",
        "      if (label_rename == newlabel_rename):\n",
        "        Reading_Img_NII = nib.load(i_img)\n",
        "        # Reading_Label_NII = nib.load(i_mask)\n",
        "\n",
        "        img_arr = Reading_Img_NII.get_fdata()\n",
        "        # mask_arr = Reading_Label_NII.get_fdata()\n",
        "        \n",
        "        # Define the new size for the resized image\n",
        "        new_size = (512, 512)\n",
        "        \n",
        "        # Resize the image using the resize() function from skimage\n",
        "        img_resized = resize(img_arr, new_size, anti_aliasing=True)\n",
        "        # mask_resized = resize(mask_arr, new_size, anti_aliasing=True)\n",
        "\n",
        "        # Rotate the image using the rotate() function from skimage\n",
        "        angle = 90\n",
        "        img_resized = rotate(img_resized , angle)\n",
        "        # mask_resized = rotate(mask_resized, angle)\n",
        "\n",
        "        img_arr_norm = (img_resized- img_resized.min()) / (img_resized.max() - img_resized.min())\n",
        "        pil_image = Image.fromarray((img_arr_norm * 255).astype(np.uint8))\n",
        "\n",
        "        # label_arr_norm = (mask_resized - mask_resized.min()) / (mask_resized .max() - mask_resized.min())\n",
        "        # pil_label = Image.fromarray((label_arr_norm* 255).astype(np.uint8))\n",
        "\n",
        "        print(i_img)\n",
        "        #save stack slices with labels\n",
        "        shutil.copy(i_img,out_img_dir )\n",
        "        # pil_image.save(f'/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack2{lbl_folder_path}/{label_rename}.png')\n",
        "  print(\"Done\")"
      ],
      "metadata": {
        "id": "fKOyr8ennH5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack\"\n",
        "output_path = \"/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack_reduced\""
      ],
      "metadata": {
        "id": "MJ8aRNqWkXZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_processor = SegformerImageProcessor(use_python_backend=False)"
      ],
      "metadata": {
        "id": "tL62LSVknrgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_data(folder_path,output_path, image_processor) #Run ONLY TWICE for stacked/label train and stacked/label test"
      ],
      "metadata": {
        "id": "gJEy_uwQ171a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_data2(folder_path,output_path) #Run 4 times for T2 and dCT2  train and T2 and dCT2l test"
      ],
      "metadata": {
        "id": "R0-DHxSSla5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data "
      ],
      "metadata": {
        "id": "nDh--Tv7JLrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPG7_vneiv41",
        "outputId": "8ef52778-92f8-4bb4-9b5a-98e3010a4d0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# folder_path = \"/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack2\" #new directory with new .png images "
      ],
      "metadata": {
        "id": "mJJt9pbsHomj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "folder_path = \"/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack_reduced\"  #new directory with new reduced .nii images "
      ],
      "metadata": {
        "id": "fRNVI-oXbTPD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### check labels "
      ],
      "metadata": {
        "id": "9x_Fe1UQAKa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sample image/label\n",
        "img_path = \"/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack2/stacked_sliced/train/P3_04_stack_Z48.png\"\n",
        "lbl_path = \"/content/drive/MyDrive/Colab_Notebooks/datasets/GoldA_ZStack2/prostate_femur_sliced/train/3_04_prostate_femur_Z48.png\"\n",
        "img = Image.open(img_path)\n",
        "label= Image.open(lbl_path)\n",
        "label_arr = np.array(label)\n",
        "print(np.unique(label_arr))\n",
        "\n",
        "#visualize image/mask\n",
        "\n",
        "# figure,axis = plt.subplots(1,2,figsize=(10,10))\n",
        "# # Plot_Color_Op = axis[0].imshow(img)\n",
        "# axis[0].imshow(img)\n",
        "# axis[0].set_xlabel(img.size)\n",
        "# axis[0].set_ylabel(img.size)\n",
        "# axis[0].set_title(\"IMAGE\")\n",
        "\n",
        "# axis[1].imshow(label)\n",
        "# axis[1].set_xlabel(label.size)\n",
        "# axis[1].set_ylabel(label.size)\n",
        "# axis[1].set_title(\"MASK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38wFh8_oK24n",
        "outputId": "f7a1d9c2-02ac-4dc0-ff60-8b0c6eee6daf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0 254 255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sample image/label\n",
        "img_path = folder_path + \"/stacked_sliced/train/P1_02_stack_Z48.nii\"\n",
        "lbl_path = folder_path + \"/prostate_femur_sliced/train/3_04_prostate_femur_Z48.nii\"\n",
        "\n",
        "\n",
        "Reading_Img_NII = nib.load(img_path)\n",
        "Reading_Label_NII = nib.load(lbl_path)\n",
        "\n",
        "img_arr = Reading_Img_NII.get_fdata()\n",
        "mask_arr = Reading_Label_NII.get_fdata()\n",
        "print(np.unique(mask_arr))\n",
        "\n",
        "#visualize image/mask\n",
        "\n",
        "# # Plot_Color_Op = axis[0].imshow(img)\n",
        "# axis[0].imshow(img)\n",
        "# axis[0].set_xlabel(img.size)\n",
        "# axis[0].set_ylabel(img.size)\n",
        "# axis[0].set_title(\"IMAGE\")\n",
        "\n",
        "# axis[1].imshow(label)\n",
        "# axis[1].set_xlabel(label.size)\n",
        "# axis[1].set_ylabel(label.size)\n",
        "# axis[1].set_title(\"MASK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii_CvgNVbaN7",
        "outputId": "b3911af7-df80-4ad4-a1a6-e6c1f697bb4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the unique labels"
      ],
      "metadata": {
        "id": "4GGsLI_OD1MU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data cleaning 1: use stacked data/ labels to get label list\n",
        "def unique_data(input_folder): \n",
        "\n",
        "  lbl_folder_path = '/prostate_femur_sliced/test'\n",
        "  label_dir = input_folder + lbl_folder_path\n",
        "\n",
        "  labels_paths = []\n",
        "  labels_paths = sorted([os.path.join(label_dir, x) for x in os.listdir(label_dir)])\n",
        "\n",
        "  for i_mask in labels_paths:\n",
        "    Reading_Label_NII = nib.load(i_mask)\n",
        "    mask_arr = Reading_Label_NII.get_fdata()\n",
        "    \n",
        "    print(np.unique(mask_arr))\n",
        "  return(\"done\")"
      ],
      "metadata": {
        "id": "k6SDp7SLeLjr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_data(folder_path)"
      ],
      "metadata": {
        "id": "_ISdAqRJeltb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "9ba8d8f9-e67f-4423-fbfb-5992bcd9285a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1.]\n",
            "[0. 1.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 1. 2.]\n",
            "[0. 2.]\n",
            "[0. 2.]\n",
            "[0. 2.]\n",
            "[0. 2.]\n",
            "[0. 2.]\n",
            "[0. 2.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load image/label directories"
      ],
      "metadata": {
        "id": "LDZSim7kAS9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## directory paths for all datasets\n",
        "\n",
        "##train\n",
        "tr_stk_img_dir=folder_path + '/stacked_sliced/train'\n",
        "tr_t2_img_dir=folder_path + '/T2_sliced/train'\n",
        "tr_dct_img_dir=folder_path + '/dCT2_sliced/train'\n",
        "tr_labels_dir=folder_path +'/prostate_femur_sliced/train'\n",
        "# tr_newlabels_dir=folder_path +'/prostate/train'\n",
        "\n",
        "##test\n",
        "ts_stk_img_dir=folder_path + '/stacked_sliced/test'\n",
        "ts_t2_img_dir=folder_path + '/T2_sliced/test'\n",
        "ts_dct_img_dir=folder_path + '/dCT2_sliced/test'\n",
        "ts_labels_dir=folder_path +'/prostate_femur_sliced/test'"
      ],
      "metadata": {
        "id": "JhUVsAK8LEpg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_stk_img_paths = sorted([os.path.join(tr_stk_img_dir, x) for x in os.listdir(tr_stk_img_dir)])\n",
        "tr_t2_img_paths = sorted([os.path.join(tr_t2_img_dir, x) for x in os.listdir(tr_t2_img_dir)])\n",
        "tr_dct_img_paths = sorted([os.path.join(tr_dct_img_dir, x) for x in os.listdir(tr_dct_img_dir)])\n",
        "tr_labels_paths = sorted([os.path.join(tr_labels_dir, x) for x in os.listdir(tr_labels_dir)])\n",
        "# tr_newlabels_paths = sorted([os.path.join(tr_newlabels_dir, x) for x in os.listdir(tr_newlabels_dir)])\n",
        "\n",
        "ts_stk_img_paths = sorted([os.path.join(ts_stk_img_dir, x) for x in os.listdir(ts_stk_img_dir)])\n",
        "ts_t2_img_paths = sorted([os.path.join(ts_t2_img_dir, x) for x in os.listdir(ts_t2_img_dir)])\n",
        "ts_dct_img_paths = sorted([os.path.join(ts_dct_img_dir, x) for x in os.listdir(ts_dct_img_dir)])\n",
        "ts_labels_paths = sorted([os.path.join(ts_labels_dir, x) for x in os.listdir(ts_labels_dir)])"
      ],
      "metadata": {
        "id": "o4AUiYSgLl2K"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check to make sure all images match with labels\n",
        "print(len(tr_stk_img_paths))\n",
        "print(len(tr_t2_img_paths))\n",
        "print(len(tr_dct_img_paths))\n",
        "print(len(tr_labels_paths))\n",
        "print(\"***\")\n",
        "print(len(ts_stk_img_paths))\n",
        "print(len(ts_t2_img_paths))\n",
        "print(len(ts_dct_img_paths))\n",
        "print(len(ts_labels_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REIb0CheLYt4",
        "outputId": "aa293197-00d0-4312-8b1e-79713ff3a6e3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "299\n",
            "299\n",
            "299\n",
            "299\n",
            "***\n",
            "51\n",
            "51\n",
            "51\n",
            "51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "To make them compatible with the SegFormer model from Hugging Face Transformers, we:\n",
        "\n",
        "- Normalize the images with the mean and standard deviation used during pre-training SegFormer.\n",
        "- Transpose the images such that they are in \"channels_first\" format. "
      ],
      "metadata": {
        "id": "G7vpL6qSL-4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pelvic segmentation class"
      ],
      "metadata": {
        "id": "MaDsADTBP-_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### .nii\n",
        "class NiftiPelvicSegmentationDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Image (pelvic) segmentation dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, img_paths, mask_paths, train=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "\n",
        "        \"\"\"\n",
        "        self.img_paths = img_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        # self.transform = transform\n",
        "        self.train = train\n",
        "\n",
        "        assert len(self.img_paths) == len(self.mask_paths), \"check that number of images equals number of segmentation masks \"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "\n",
        "        #Load the Nifti image      \n",
        "        img = nib.load(self.img_paths[idx])\n",
        "        mask = nib.load(self.mask_paths[idx])\n",
        "\n",
        "        # Convert the Nifti image to a NumPy array\n",
        "        img_arr = img.get_fdata()\n",
        "        mask_arr = mask.get_fdata()\n",
        "\n",
        "        # Define the new size for the resized image\n",
        "        if (img_arr.shape != (512, 512)):\n",
        "          new_size = (512, 512)\n",
        "          # Resize the image using the resize() function from skimage\n",
        "          img_arr= resize(img_arr, new_size, anti_aliasing=True)\n",
        "          mask_arr = resize(mask_arr, new_size, anti_aliasing=True)\n",
        "\n",
        "        #Normalize the image\n",
        "        img_arr = (img_arr - img_arr.min()) / (img_arr.max() - img_arr.min())\n",
        "        img_arr = np.stack([img_arr ] * 3, axis=-1).transpose((2,1,0))\n",
        "\n",
        "        # if self.transform is not None:\n",
        "        #     img_arr = self.transform(img_arr)\n",
        "        #     mask_arr = self.transform(mask_arr)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        img_tensor = torch.from_numpy(img_arr).unsqueeze(0) # Add channel dimension\n",
        "        mask_tensor = torch.from_numpy(mask_arr).unsqueeze(0) # Add channel dimension\n",
        "\n",
        "        # pad both image and segmentation map to same size\n",
        "        inputs = {\"pixel_values\": img_tensor.squeeze_().float(), \"labels\": mask_tensor.squeeze_().long()}\n",
        "\n",
        "        return inputs"
      ],
      "metadata": {
        "id": "gk09HBB-CFnb"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NiftiPelvicSegmentationDataset(img_paths=tr_stk_img_paths, mask_paths=tr_labels_paths)\n",
        "valid_dataset = NiftiPelvicSegmentationDataset(img_paths=ts_stk_img_paths, mask_paths=ts_labels_paths, train=False)"
      ],
      "metadata": {
        "id": "orn6An_jDcRT"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### check data "
      ],
      "metadata": {
        "id": "iSBPp5FxWKQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"# of training data:\", len(train_dataset))\n",
        "print(\"# of test data:\", len(valid_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QayeLGrSWAeN",
        "outputId": "d97a2372-0eba-4569-d3ed-8ad0e878e90e"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of training data: 299\n",
            "# of test data: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_inputs = train_dataset[0]\n",
        "print(encoded_inputs[\"pixel_values\"].shape)\n",
        "print(encoded_inputs[\"labels\"].shape)\n",
        "print(encoded_inputs[\"labels\"].squeeze().unique())"
      ],
      "metadata": {
        "id": "QIeGTqwMWGwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbb9a47-b114-47c7-8d5a-43fac95696e1"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 512, 512])\n",
            "torch.Size([512, 512])\n",
            "tensor([0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the labels "
      ],
      "metadata": {
        "id": "myPtuOdlMJO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_labels = set()\n",
        "unique_pixels_list = []\n",
        "#train data\n",
        "for i in range(len(train_dataset)):\n",
        "  unique_pixels = train_dataset[i][\"labels\"].squeeze().unique()\n",
        "  if str(unique_pixels) not in unique_pixels_list:\n",
        "    unique_pixels_list.append(str(unique_pixels))\n",
        "\n",
        "#test data\n",
        "for i in range(len(valid_dataset)):\n",
        "  unique_pixels = valid_dataset[i][\"labels\"].squeeze().unique()\n",
        "  if str(unique_pixels) not in unique_pixels_list:\n",
        "    unique_pixels_list.append(str(unique_pixels))\n",
        "\n",
        "print(len(unique_pixels_list))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEgPY_xYM_qb",
        "outputId": "dc7212f4-f9c5-4dc5-9518-bb61d5f6c0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"labels\"].shape"
      ],
      "metadata": {
        "id": "ycV1jCqPbNZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning the model"
      ],
      "metadata": {
        "id": "iDI4MAp2bXrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set labels\n",
        "import json\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# hf_dataset_identifier = \"Cats-Can/image_data\"\n",
        "\n",
        "# filename = \"id2label.json\"\n",
        "# id2label = json.load(open(hf_hub_download(repo_id=hf_dataset_identifier, filename=filename, repo_type=\"dataset\"), \"r\"))\n",
        "id2label = {0: 'Background',  1: 'Prostate', 2: 'Femur'} #uncomment to use if having problems with HF\n",
        "id2label = {int(k): v for k, v in id2label.items()}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "num_labels = len(id2label)\n",
        "print(\"Id2label:\", id2label)\n",
        "print(num_labels)"
      ],
      "metadata": {
        "id": "U8qBNrRkbQ_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d174fc4-eb1e-4e6c-b088-4ff417444d31"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id2label: {0: 'Background', 1: 'Prostate', 2: 'Femur'}\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "from transformers import SegformerForSemanticSegmentation"
      ],
      "metadata": {
        "id": "ATL6GQrInFX5"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b0\",\n",
        "                                                         num_labels=3, \n",
        "                                                         id2label=id2label, \n",
        "                                                         label2id=label2id,\n",
        ")"
      ],
      "metadata": {
        "id": "x5THlV3kbRjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9daf22b1-7b6f-4315-c37d-b802e2db147c"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.3.proj.bias', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.2.proj.bias', 'decode_head.batch_norm.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.classifier.bias', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.weight', 'decode_head.classifier.weight', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.3.proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"mean_iou\", \"erntkn/dice_coefficient\")"
      ],
      "metadata": {
        "id": "ZXQkNGK0noVn"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import list_metrics\n",
        "list_metrics()"
      ],
      "metadata": {
        "id": "49dK7r_OgzBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "epochs = 1\n",
        "lr = 0.00006\n",
        "batch_size = 4\n",
        "\n",
        "hub_model_id = \"segformer-b0-finetuned-pelvic-segmentation\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    \"segformer-b0-finetuned-pelvic-outputs\",\n",
        "    learning_rate=lr,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    save_total_limit=3,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=20,\n",
        "    eval_steps=20,\n",
        "    logging_steps=1,\n",
        "    eval_accumulation_steps=5,\n",
        "    load_best_model_at_end=True,\n",
        "    # push_to_hub=True,\n",
        "    # hub_model_id=hub_model_id,\n",
        "    # hub_strategy=\"end\",\n",
        ")"
      ],
      "metadata": {
        "id": "-WhM70c1IqIR"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  with torch.no_grad():\n",
        "    logits, labels = eval_pred\n",
        "    logits_tensor = torch.from_numpy(logits)\n",
        "\n",
        "    # scale the logits to the size of the label\n",
        "    logits_tensor = nn.functional.interpolate(\n",
        "        logits_tensor,\n",
        "        size=labels.shape[-2:],\n",
        "        mode=\"bilinear\",\n",
        "        align_corners=False,\n",
        "    ).argmax(dim=1)\n",
        "\n",
        "    pred_labels = logits_tensor.detach().cpu().numpy()\n",
        "    metrics = metric._compute(\n",
        "            predictions=pred_labels,\n",
        "            references=labels,\n",
        "            num_labels=len(id2label),\n",
        "            ignore_index=0,\n",
        "\n",
        "        )\n",
        "    \n",
        "    # add per category metrics as individual key-value pairs\n",
        "    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()   \n",
        "    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
        "\n",
        "\n",
        "\n",
        "    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
        "    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "sXNu723CIqMY"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "nPSof7vJk30w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "iw-g2Nz3I1bS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEPG1HR4p+WlPLfpwSLTvL",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57d26d2a0c85483b819b730428df1db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_076aa2d8a1c24cf29e0382a5f50d1c5c",
              "IPY_MODEL_d46143b4c50946c6ac4dfe35dadd2769",
              "IPY_MODEL_001e152e0aa045a7900e9391cd28d65b",
              "IPY_MODEL_316c9759bc0643a5b60ea75d785a37e1",
              "IPY_MODEL_a5800fd8a0ac4c5580b04d62d5bf16c7"
            ],
            "layout": "IPY_MODEL_1d478e1dbd834648ba8bd481a1945c04"
          }
        },
        "076aa2d8a1c24cf29e0382a5f50d1c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_870e2d453d794cc0be3b4a7486cb73ab",
            "placeholder": "​",
            "style": "IPY_MODEL_af909819456049cba15fb2d19b76cea1",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "d46143b4c50946c6ac4dfe35dadd2769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f9d92b91ce2b4291bbddd5231e214d53",
            "placeholder": "​",
            "style": "IPY_MODEL_8359b8b4acb348d8ad95d5cdca5b26a8",
            "value": ""
          }
        },
        "001e152e0aa045a7900e9391cd28d65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_9a7b8641acc34bf289663fc9ca4e193a",
            "style": "IPY_MODEL_26581b71da7a45bd88f0ad5968abe28c",
            "value": true
          }
        },
        "316c9759bc0643a5b60ea75d785a37e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9671295fb7df4ea88365046e939b662b",
            "style": "IPY_MODEL_2a4867ca09b348f6b962d4cc345956de",
            "tooltip": ""
          }
        },
        "a5800fd8a0ac4c5580b04d62d5bf16c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132603c40cc9487eb6c9fe5fe711bd64",
            "placeholder": "​",
            "style": "IPY_MODEL_52455886f6f24be8a8f07fe1ed8a1786",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "1d478e1dbd834648ba8bd481a1945c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "870e2d453d794cc0be3b4a7486cb73ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af909819456049cba15fb2d19b76cea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9d92b91ce2b4291bbddd5231e214d53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8359b8b4acb348d8ad95d5cdca5b26a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a7b8641acc34bf289663fc9ca4e193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26581b71da7a45bd88f0ad5968abe28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9671295fb7df4ea88365046e939b662b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4867ca09b348f6b962d4cc345956de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "132603c40cc9487eb6c9fe5fe711bd64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52455886f6f24be8a8f07fe1ed8a1786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}